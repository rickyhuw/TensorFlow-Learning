{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sklearn 0.20.2\n",
      "pandas 0.24.2\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n",
      "numpy 1.17.4\n",
      "matplotlib 2.1.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(tf.__version__)\n",
    "for model in sklearn, pd, keras, np ,mlp:\n",
    "    print(model.__name__, model.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "housing = fetch_california_housing()\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=1)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state=2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 0.2 数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "x_train = std.fit_transform(x_train)\n",
    "x_valid = std.transform(x_valid)\n",
    "x_test = std.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.models.Sequential()\n",
    "# version dnn, 多层神经网络，循环添加层次。\n",
    "# 使用sklearn进行随机超参数搜索\n",
    "# 1. 转化成sklearn的model\n",
    "def build_model(hidden_layers=1,\n",
    "                layer_size=30,\n",
    "                learning_rate=3e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(layer_size, \n",
    "                                 input_shape=x_train.shape[1:]))\n",
    "    for _ in range(hidden_layers -1):\n",
    "        model.add(keras.layers.Dense(layer_size, activation='relu'))\n",
    "        \n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    model.compile(loss='mse',optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 0.3 回调函数\n",
    "# Tensorboard, Earlystopping, Modelcheckpoint\n",
    "logdir = './reg_search_callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir,\n",
    "                                 \"housing_model.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)\n",
    "]\n",
    "\n",
    "sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.9468 - val_loss: 0.5263\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.7093 - val_loss: 0.5293\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5375 - val_loss: 0.5660\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5815 - val_loss: 0.5349\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5781 - val_loss: 0.5305\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5335 - val_loss: 0.5254\n"
     ]
    }
   ],
   "source": [
    "history = sklearn_model.fit(x_train, y_train, epochs=10,validation_data=(x_valid, y_valid),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14263f400>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 102us/sample - loss: 0.7765 - val_loss: 0.4667\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5848 - val_loss: 0.4828\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4538 - val_loss: 0.4279\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5833 - val_loss: 0.4519\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5527 - val_loss: 0.4266\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4769 - val_loss: 0.4376\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.1888 - val_loss: 0.4400\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4233 - val_loss: 0.4328\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3917 - val_loss: 0.3994\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3834 - val_loss: 0.3685\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.3903\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3525\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 114us/sample - loss: 0.7224 - val_loss: 0.4518\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 1.7318 - val_loss: 0.5322\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5184 - val_loss: 0.4122\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5250 - val_loss: 0.5108\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5245 - val_loss: 0.4356\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 2.2493 - val_loss: 0.4557\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.4628 - val_loss: 0.4268\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5987 - val_loss: 0.4540\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.4462\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6235\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 0.6563 - val_loss: 0.4440\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4606 - val_loss: 0.4048\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4288 - val_loss: 0.4451\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 2.4690 - val_loss: 0.4466\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 64.9765 - val_loss: 0.4684\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 30.7304 - val_loss: 0.7946\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5137 - val_loss: 0.4296\n",
      "3870/3870 [==============================] - 0s 28us/sample - loss: 0.4390\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4364\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.6991 - val_loss: 0.4852\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 2.6375 - val_loss: 0.4934\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5596 - val_loss: 0.4681\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 1.3770 - val_loss: 0.4925\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 1.5150 - val_loss: 0.5065\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5189 - val_loss: 0.4554\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5158 - val_loss: 0.4417\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6385 - val_loss: 0.6599\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6729 - val_loss: 0.5380\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5541 - val_loss: 0.4665\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4912\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.4643\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 1.1184 - val_loss: 0.9308\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5686 - val_loss: 0.4312\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4587 - val_loss: 0.6336\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4484 - val_loss: 0.4390\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4948 - val_loss: 0.4284\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4046 - val_loss: 0.3831\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3973 - val_loss: 0.3828\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3836 - val_loss: 0.3542\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.3967 - val_loss: 0.3326\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3652 - val_loss: 0.3341\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.3807\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.3418\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.6851 - val_loss: 0.4451\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5330 - val_loss: 0.4408\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4559 - val_loss: 0.4418\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4131 - val_loss: 0.5884\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5703 - val_loss: 0.4465\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5278 - val_loss: 0.4330\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4269 - val_loss: 0.3989\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4327 - val_loss: 0.4022\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4032 - val_loss: 0.3841\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4007 - val_loss: 0.4459\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4589\n",
      "7740/7740 [==============================] - 0s 19us/sample - loss: 0.4397\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 151us/sample - loss: 4.4174 - val_loss: 3.4746\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.8156 - val_loss: 2.1697\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.6883 - val_loss: 1.2648\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.9873 - val_loss: 0.7824\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6637 - val_loss: 0.6004\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5622 - val_loss: 0.5511\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5379 - val_loss: 0.5375\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5278 - val_loss: 0.5309\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5262 - val_loss: 0.5268\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5219 - val_loss: 0.5250\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.5541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 18us/sample - loss: 0.5173\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 5.0639 - val_loss: 3.7373\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 2.8870 - val_loss: 2.0815\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.5914 - val_loss: 1.1652\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.9353 - val_loss: 0.7537\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6721 - val_loss: 0.6145\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5898 - val_loss: 0.5735\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5648 - val_loss: 0.5564\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5529 - val_loss: 0.5475\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5451 - val_loss: 0.5407\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5409 - val_loss: 0.5347\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.5173\n",
      "7740/7740 [==============================] - 0s 18us/sample - loss: 0.5383\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 4.5453 - val_loss: 3.4251\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 2.5848 - val_loss: 1.9020\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.3739 - val_loss: 0.9938\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.7617 - val_loss: 0.6361\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5712 - val_loss: 0.5534\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5381 - val_loss: 0.5389\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5352 - val_loss: 0.5353\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5326 - val_loss: 0.5326\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5297 - val_loss: 0.5327\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5328 - val_loss: 0.5309\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5301\n",
      "7740/7740 [==============================] - 0s 18us/sample - loss: 0.5261\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 3.1604 - val_loss: 0.5201\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.8112 - val_loss: 0.5196\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5532 - val_loss: 0.5206\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6162 - val_loss: 0.5325\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5465 - val_loss: 0.5360\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5662 - val_loss: 0.5336\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.5561\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5254\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 1.8385 - val_loss: 0.5443\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5729 - val_loss: 0.5258\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5584 - val_loss: 0.5243\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5437 - val_loss: 0.5347\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5520 - val_loss: 0.5369\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5593 - val_loss: 0.5382\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6425 - val_loss: 0.5258\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5512 - val_loss: 0.5293\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5365\n",
      "7740/7740 [==============================] - 0s 18us/sample - loss: 0.5638\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 1.2083 - val_loss: 0.5324\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5435 - val_loss: 0.5416\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5569 - val_loss: 0.7602\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.9577 - val_loss: 0.5797\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6126 - val_loss: 0.5339\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5391 - val_loss: 0.5335\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5348\n",
      "7740/7740 [==============================] - 0s 18us/sample - loss: 0.5316\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 1.3456 - val_loss: 0.7212\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6358 - val_loss: 0.5445\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5303 - val_loss: 0.4720\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5423 - val_loss: 0.4625\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4534 - val_loss: 0.4465\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4431 - val_loss: 0.4388\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4356 - val_loss: 0.4343\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4261 - val_loss: 0.4421\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4366 - val_loss: 0.4196\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4230 - val_loss: 0.4189\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4459\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.4406\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 1.4746 - val_loss: 0.7395\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6373 - val_loss: 0.5434\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6016 - val_loss: 0.4832\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4807 - val_loss: 0.4634\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4725 - val_loss: 0.4501\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4590 - val_loss: 0.4381\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4442 - val_loss: 0.4327\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4384 - val_loss: 0.4261\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4423 - val_loss: 0.4402\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4348 - val_loss: 0.4220\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.4047\n",
      "7740/7740 [==============================] - 0s 19us/sample - loss: 0.4170\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 1.4583 - val_loss: 0.7464\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6410 - val_loss: 0.5577\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5368 - val_loss: 0.4719\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4797 - val_loss: 0.4814\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.5183 - val_loss: 0.4360\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4397 - val_loss: 0.4375\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4375 - val_loss: 0.4288\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4210 - val_loss: 0.4205\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4124 - val_loss: 0.4196\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4227 - val_loss: 0.4182\n",
      "3870/3870 [==============================] - 0s 26us/sample - loss: 0.5076\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4168\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 1.1533 - val_loss: 0.4715\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4453 - val_loss: 0.4123\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4028 - val_loss: 0.4030\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3937 - val_loss: 0.3746\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3712 - val_loss: 0.4028\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3583 - val_loss: 0.3507\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3521 - val_loss: 0.3809\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3384 - val_loss: 0.3340\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3423 - val_loss: 0.3645\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3246 - val_loss: 0.3338\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3406\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.3061\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 1.1710 - val_loss: 0.5378\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4632 - val_loss: 0.4151\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4176 - val_loss: 0.4227\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4133 - val_loss: 0.4005\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3709 - val_loss: 0.3726\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3626 - val_loss: 0.3595\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3535 - val_loss: 0.3473\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3491 - val_loss: 0.3731\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3351 - val_loss: 0.3267\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3270 - val_loss: 0.3307\n",
      "3870/3870 [==============================] - 0s 27us/sample - loss: 0.3171\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3158\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 111us/sample - loss: 0.8960 - val_loss: 0.4693\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4294 - val_loss: 0.4030\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3929 - val_loss: 0.3734\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3685 - val_loss: 0.3757\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3520 - val_loss: 0.3559\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3385 - val_loss: 0.3316\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3366 - val_loss: 0.3275\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3428 - val_loss: 0.3232\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3195 - val_loss: 0.3258\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3166 - val_loss: 0.3385\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.3714\n",
      "7740/7740 [==============================] - 0s 20us/sample - loss: 0.3198\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 115us/sample - loss: 1.6939 - val_loss: 0.7638\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.7195 - val_loss: 0.6031\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.5510 - val_loss: 0.4880\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4595 - val_loss: 0.4361\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4215 - val_loss: 0.4139\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3989 - val_loss: 0.4031\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3869 - val_loss: 0.3906\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3807 - val_loss: 0.3816\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.3709 - val_loss: 0.3767\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3636 - val_loss: 0.3713\n",
      "3870/3870 [==============================] - 0s 30us/sample - loss: 0.3803\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3524\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 145us/sample - loss: 1.7625 - val_loss: 0.7475\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.7562 - val_loss: 0.6037\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.5827 - val_loss: 0.5102\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.4954 - val_loss: 0.4595\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.4523 - val_loss: 0.4310\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 0.4300 - val_loss: 0.4173\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.4134 - val_loss: 0.4069\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.4035 - val_loss: 0.3953\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.3940 - val_loss: 0.3875\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.3844 - val_loss: 0.3875\n",
      "3870/3870 [==============================] - 0s 32us/sample - loss: 0.3694\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3805\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 163us/sample - loss: 2.0157 - val_loss: 0.7124\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 0.6512 - val_loss: 0.5617\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.5272 - val_loss: 0.4902\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.4679 - val_loss: 0.4539\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.4377 - val_loss: 0.4336\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.4191 - val_loss: 0.4141\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.4054 - val_loss: 0.4027\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3933 - val_loss: 0.3975\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3841 - val_loss: 0.3852\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3777 - val_loss: 0.3786\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.3924\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3715\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 1.5902 - val_loss: 0.6353\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5684 - val_loss: 0.5635\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5975 - val_loss: 0.5309\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5359 - val_loss: 0.6209\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.6475 - val_loss: 0.5914\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7959 - val_loss: 0.5154\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.7337 - val_loss: 0.5601\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.6305 - val_loss: 0.5195\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5725 - val_loss: 0.5487\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5274 - val_loss: 0.5252\n",
      "3870/3870 [==============================] - 0s 24us/sample - loss: 0.5446\n",
      "7740/7740 [==============================] - 0s 21us/sample - loss: 0.5205\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 12.1059 - val_loss: 0.6815\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 2.3510 - val_loss: 0.5932\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.7366 - val_loss: 0.5256\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5536 - val_loss: 0.5214\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5324 - val_loss: 0.5237\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5492 - val_loss: 0.5397\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5462 - val_loss: 0.5207\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5623 - val_loss: 0.5241\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5437 - val_loss: 0.5313\n",
      "3870/3870 [==============================] - 0s 23us/sample - loss: 0.6538\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5625\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 1.4722 - val_loss: 0.5186\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6824 - val_loss: 0.5522\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5390 - val_loss: 0.5306\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5744 - val_loss: 0.5692\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5433 - val_loss: 0.5296\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5678 - val_loss: 0.5282\n",
      "3870/3870 [==============================] - 0s 26us/sample - loss: 0.5424\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5369\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 4.3844 - val_loss: 2.7754\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 1.9790 - val_loss: 1.3019\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.9719 - val_loss: 0.7619\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6664 - val_loss: 0.6275\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5867 - val_loss: 0.5805\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5538 - val_loss: 0.5544\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5344 - val_loss: 0.5390\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5240 - val_loss: 0.5271\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5241 - val_loss: 0.5264\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5230 - val_loss: 0.5253\n",
      "3870/3870 [==============================] - 0s 19us/sample - loss: 0.5536\n",
      "7740/7740 [==============================] - 0s 18us/sample - loss: 0.5172\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 109us/sample - loss: 4.4197 - val_loss: 2.8289\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 2.3677 - val_loss: 1.4409\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 1.2447 - val_loss: 0.7712\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.7557 - val_loss: 0.5684\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6041 - val_loss: 0.5335\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5626 - val_loss: 0.5286\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5446 - val_loss: 0.5257\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5364 - val_loss: 0.5250\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5317 - val_loss: 0.5229\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5300 - val_loss: 0.5223\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.5151\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5288\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 3.6304 - val_loss: 2.3815\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.5067 - val_loss: 0.9028\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.6645 - val_loss: 0.5675\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5408 - val_loss: 0.5426\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5370 - val_loss: 0.5366\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5373 - val_loss: 0.5353\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5372 - val_loss: 0.5344\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5316 - val_loss: 0.5306\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5307 - val_loss: 0.5298\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5333 - val_loss: 0.5284\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.5265\n",
      "7740/7740 [==============================] - 0s 16us/sample - loss: 0.5280\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 1.6341 - val_loss: 0.6801\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6087 - val_loss: 0.5408\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6189 - val_loss: 0.4807\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4812 - val_loss: 0.4675\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4459 - val_loss: 0.4482\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4301 - val_loss: 0.4271\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4114 - val_loss: 0.4116\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4001 - val_loss: 0.3947\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3850 - val_loss: 0.3802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.3954 - val_loss: 0.3857\n",
      "3870/3870 [==============================] - 0s 17us/sample - loss: 0.4010\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.3803\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 2.4401 - val_loss: 0.5845\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.6360 - val_loss: 0.5366\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5566 - val_loss: 0.5125\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5603 - val_loss: 0.4816\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4928 - val_loss: 0.4780\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4856 - val_loss: 0.4820\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4799 - val_loss: 0.4644\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4720 - val_loss: 0.4558\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4811 - val_loss: 0.4599\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4704 - val_loss: 0.4571\n",
      "3870/3870 [==============================] - 0s 15us/sample - loss: 0.4374\n",
      "7740/7740 [==============================] - 0s 16us/sample - loss: 0.4587\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 1.2577 - val_loss: 0.4842\n",
      "Epoch 2/10\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4643 - val_loss: 0.4439\n",
      "Epoch 3/10\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4430 - val_loss: 0.4171\n",
      "Epoch 4/10\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4145 - val_loss: 0.4004\n",
      "Epoch 5/10\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3991 - val_loss: 0.4100\n",
      "Epoch 6/10\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4027 - val_loss: 0.3924\n",
      "Epoch 7/10\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3919 - val_loss: 0.3936\n",
      "Epoch 8/10\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3884 - val_loss: 0.4048\n",
      "Epoch 9/10\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3902 - val_loss: 0.3846\n",
      "Epoch 10/10\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.3830 - val_loss: 0.3805\n",
      "3870/3870 [==============================] - 0s 16us/sample - loss: 0.4001\n",
      "7740/7740 [==============================] - 0s 15us/sample - loss: 0.3762\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 77us/sample - loss: 0.8324 - val_loss: 0.4402\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4164 - val_loss: 0.3889\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3867 - val_loss: 0.3636\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3663 - val_loss: 0.3629\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3534 - val_loss: 0.3354\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3376 - val_loss: 0.3472\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3272 - val_loss: 0.3174\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3126 - val_loss: 0.3159\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3118 - val_loss: 0.3123\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3130 - val_loss: 0.3252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x141b0d908>,\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=1,\n",
       "          param_distributions={'hidden_layers': [1, 2, 3, 4], 'layer_size': array([ 1,  2, ..., 98, 99]), 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1487daa58>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用sklearn中的函数进行搜索\n",
    "from scipy.stats import reciprocal\n",
    "param_distribution = {\n",
    "    \"hidden_layers\":[1, 2, 3, 4],\n",
    "    \"layer_size\":np.arange(1,100),\n",
    "    \"learning_rate\":reciprocal(1e-4, 1e-2)\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search_cv = RandomizedSearchCV(sklearn_model,\n",
    "                                      param_distributions=param_distribution,\n",
    "                                      n_iter=10,\n",
    "                                      n_jobs=1)\n",
    "\n",
    "random_search_cv.fit(x_train, y_train, epochs=10,validation_data=(x_valid, y_valid),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layers': 2, 'layer_size': 98, 'learning_rate': 0.0024378872676702953}\n",
      "-0.37408522249910975\n",
      "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x148667ba8>\n"
     ]
    }
   ],
   "source": [
    "print(random_search_cv.best_params_)\n",
    "print(random_search_cv.best_score_)\n",
    "print(random_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 27us/sample - loss: 0.3813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38133598880250325"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = random_search_cv.best_estimator_.model\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
